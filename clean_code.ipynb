{"cells":[{"cell_type":"markdown","metadata":{"id":"CaTBLDib0Xim"},"source":["# TFM\n","Graph Convolutional Networks for Human Identification Based on Multichannel ECG Signals\n","--------------------------\n","José Ignacio Díez Ruiz (100487766)"]},{"cell_type":"markdown","metadata":{"id":"ull_Nc0crG2m"},"source":["## Set up"]},{"cell_type":"markdown","metadata":{"id":"5SVHDoASIh3N"},"source":["### Colab set-up"]},{"cell_type":"markdown","metadata":{"id":"jeW3FZQgLOHf"},"source":["#### Mounting colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28404,"status":"ok","timestamp":1694528449609,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"rG-Q0efcLQRK","outputId":"00cecce6-9718-446e-aff0-cce0b0343df2"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"aZPXEWt2I5sB"},"source":["#### Installing pytorch geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54156,"status":"ok","timestamp":1694528580189,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"OA8v57Mw0fAb","outputId":"e1ef52a9-297a-4437-83e8-5d8b2c4161fd"},"outputs":[],"source":["import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","CUDA = format_cuda_version(CUDA_version)\n","\n","%pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","%pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","%pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","%pip install torch-spline-conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n","%pip install torch-geometric\n","%pip install torch-geometric-temporal"]},{"cell_type":"markdown","metadata":{"id":"_UUXWKv9LfqV"},"source":["### Generic set-up"]},{"cell_type":"markdown","metadata":{"id":"1_fLDcvCI9Qp"},"source":["#### Loading required packages"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5251,"status":"ok","timestamp":1694528612795,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"GnOeaPRr0Xin"},"outputs":[],"source":["import os\n","import numpy as np\n","from scipy import signal\n","from tqdm import tqdm\n","from sklearn.metrics import mutual_info_score\n","from scipy.io import loadmat\n","from keras.utils import pad_sequences\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","import torch\n","from torch import nn\n","from torch.nn import Conv1d, MaxPool1d, Linear, Dropout\n","import torch.nn.functional as F\n","\n","import torch_geometric as tg\n","from torch_geometric.nn import GCNConv, global_mean_pool, global_sort_pool\n","from torch_geometric.utils import remove_self_loops\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","\n","from torch_geometric_temporal.nn.recurrent import GConvGRU\n","# ----- seting the device and seeds -----------------------------------\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","np.random.seed(33)\n","torch.manual_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"ihXg0l0CJISA"},"source":["#### Helper functions definition"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1694528649963,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"yzJO62t40Xip"},"outputs":[],"source":["def load_mat(filename):\n","    \"\"\"Loads a .mat file as a numpy array\"\"\"\n","    x = loadmat(filename)\n","    data = np.asarray(x['val'], dtype=np.float64)\n","    return data\n","\n","def import_ecg_data(directory, seconds_per_window=5, default_window_size=128, n_files_to_load=None):\n","    \"\"\"\n","    Imports all .mat file containing ECG data of a given directory as a list.\n","    It also returns the names of the loaded files, as they may be useful to\n","    use as labels.\n","\n","    When the next window is smaller than thw given window size, the\n","    function skips to the next sample.\n","\n","    Parameters\n","    ----------\n","    directory: string or Path\n","        Path where .mat files are stored\n","    seconds_per_window: int\n","        Number of seconds to take for every window\n","    default_window_size: int\n","        Number of samples for every window.\n","        Only used if no .hea file in found in the directory\n","        with metadata.\n","    n_files_to_load: int\n","        Number of files to load in the directory.\n","        If no number is specificied, all files will be loaded.\n","        If a number is specified, the load of the files\n","        will be in alphabetic order.\n","    trunc:\n","    pad:\n","    \"\"\"\n","    print(\"Starting ECG import...\")\n","    ecgs = []\n","    filenames = []\n","    files_loaded = 0\n","    for ecgfilename in tqdm(sorted(os.listdir(directory))):\n","        filepath = directory + os.sep + ecgfilename\n","        if filepath.endswith(\".mat\"):\n","            try:\n","                hea_filepath = directory + os.sep + Path(filepath).stem + \".hea\"\n","                with open(hea_filepath, \"r\") as f:\n","                    sampling_frequency = int(f.readline().split()[2]) # number of samples per second\n","                    window_size = sampling_frequency * seconds_per_window\n","            except Exception as e:\n","                window_size = default_window_size * seconds_per_window\n","            data = load_mat(filepath)\n","            current_index = 0\n","            previous_index = 0\n","            while current_index <= (data[0].shape[0] - window_size):\n","                current_index += window_size\n","                window = data[:,previous_index:current_index]\n","                window = pad_sequences(window, truncating=\"post\", padding=\"post\")\n","                ecgs.append(window)\n","                filenames.append(ecgfilename.split(\".\")[0])\n","                previous_index = current_index\n","            files_loaded += 1\n","            if n_files_to_load is not None and files_loaded == n_files_to_load:\n","                break\n","    print(\"Finished!\")\n","    return ecgs, filenames\n","\n","def calc_MI_matrix(data, bins=200):\n","    \"\"\"\n","    It computes the Mutual Information matrix for 2 variables\n","\n","    Parameters\n","    ----------\n","    data: numpy ndarray with 2 dimensions\n","        Where the data of the variables is stored\n","    bins: int\n","        Number of bins of the histogram used to estimate the mutual information score.\n","        Default: 200\n","    \"\"\"\n","    dims = data.shape[0]\n","    mi_matrix = np.zeros((dims,dims))\n","\n","    for i in range(dims):\n","        for j in range(dims):\n","            x = np.array(data[i])\n","            y = np.array(data[j])\n","            c_xy = np.histogram2d(x, y, bins)[0]\n","\n","            mi_matrix[i,j] = mutual_info_score(None, None, contingency=c_xy)\n","\n","    return mi_matrix\n","\n","def train(train_loader, edge_weights=True):\n","    \"\"\"\n","    It trains a pytorch geometric model.\n","\n","    \"\"\"\n","    model.train()\n","\n","    for data in train_loader:\n","        data = data.to(device)\n","        if edge_weights:\n","            outputs = model(data.x, data.edge_index, data.edge_weight, data.batch)\n","        else:\n","            outputs = model(data.x, data.edge_index, data.batch)\n","        loss = criterion(outputs, data.y.long())\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","\n","def test(loader, edge_weights=True):\n","    \"\"\"\n","    It tests a pytorch_geometric model for a given loader.\n","\n","    \"\"\"\n","    model.eval()\n","\n","    total_correct  = 0\n","    total_samples  = 0\n","    true_positive  = [0] * num_classes\n","    false_positive = [0] * num_classes\n","    false_negative = [0] * num_classes\n","    CM = 0 # define an empty confussion matrix\n","\n","    for data in loader:  # Iterate in batches over the training/test dataset.\n","        data = data.to(device)\n","        if edge_weights:\n","            outputs = model(data.x, data.edge_index, data.edge_weight, data.batch)\n","        else:\n","            outputs = model(data.x, data.edge_index, data.batch)\n","        preds = outputs.argmax(dim=1)  # Use the class with highest probability.\n","        total_correct += int((preds == data.y).sum())  # Check against ground-truth labels.\n","        total_samples += len(data.y)\n","        CM += confusion_matrix(data.y.cpu(), preds.cpu(), labels=np.unique(labels))\n","        for i in range(num_classes):\n","            true_positive[i]  += ((preds == i) & (data.y == i)).sum().item()\n","            false_positive[i] += ((preds == i) & (data.y != i)).sum().item()\n","            false_negative[i] += ((preds != i) & (data.y == i)).sum().item()\n","\n","    accuracy    = total_correct / total_samples\n","    precision   = [tp / (tp + fp + 1e-6) for tp, fp in zip(true_positive, false_positive)]\n","    recall      = [tp / (tp + fn + 1e-6) for tp, fn in zip(true_positive, false_negative)]\n","    f1_scores   = [2 * (pr * re) / (pr + re + 1e-6) for pr, re in zip(precision, recall)]\n","\n","    return accuracy, precision, recall, f1_scores, CM\n","\n","def pyg_ei_fc(num_nodes, self_loops=True):\n","    \"\"\"\n","    Edge index matrix generator for a fully connected graph in pytorch geometric format\n","\n","    Parameters\n","    ----------\n","    num_nodes: int\n","        Number of nodes of the graph.\n","    self_lopps: bool\n","        If the graph has self loops or not.\n","    \"\"\"\n","    \n","    # Generate all possible combinations of edges (complete graph)\n","    if self_loops:\n","        edges = [(i, j) for i in range(num_nodes) for j in range(num_nodes)]\n","    else:\n","        edges = [(i, j) for i in range(num_nodes) for j in range(num_nodes) if i != j]\n","\n","    # Separate the source and target nodes into two separate lists\n","    src, tgt = zip(*edges)\n","\n","    # Convert the lists to PyTorch tensors\n","    src = torch.tensor(src, dtype=torch.long)\n","    tgt = torch.tensor(tgt, dtype=torch.long)\n","\n","    # Concatenate the source and target tensors to create the edge index\n","    edge_index = torch.stack([src, tgt], dim=0)\n","\n","    return edge_index\n","\n","def indices_generator(first, last, proportion):\n","    \"\"\"\n","    Generates non-overlaping train and test indices in range [first, last] (both inclusive)\n","    \"\"\"\n","    n = round(num_ecg_signals * proportion)\n","\n","    # n random indices in the range\n","    train_indices = np.random.randint(first, last, n)\n","    train_indices = np.random.choice(np.arange(first, last), size=n, replace=False)\n","\n","    # obtain the complementary of the set\n","    all_indices = np.arange(first, last)\n","    test_indices = np.setdiff1d(all_indices, train_indices)\n","\n","    return train_indices, test_indices"]},{"cell_type":"markdown","metadata":{"id":"pvCThzvhNEzS"},"source":["## Some GNN Architectures Examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aI97idvNEzS"},"outputs":[],"source":["class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(GCN, self).__init__()\n","        torch.manual_seed(33)\n","        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","        self.lin = Linear(hidden_channels, num_classes) # dataset.num_classes\n","\n","    def forward(self, x, edge_index, edge_weight, batch):\n","        x = self.conv1(x, edge_index, edge_weight)\n","        x = x.relu()\n","        x = self.conv2(x, edge_index, edge_weight)\n","\n","        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n","\n","        x = F.dropout(x, p=0.3, training=self.training)\n","        x = self.lin(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5yBgAQGNEzS"},"outputs":[],"source":["class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(GCN, self).__init__()\n","        torch.manual_seed(33)\n","        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n","        self.lin = Linear(hidden_channels, num_classes) # dataset.num_classes\n","\n","    def forward(self, x, edge_index, batch):\n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = self.conv2(x, edge_index)\n","        x = x.relu()\n","        x = self.conv3(x, edge_index)\n","\n","        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n","\n","        x = F.dropout(x, p=0.3, training=self.training)\n","        x = self.lin(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dh7AtZQNEzS"},"outputs":[],"source":["class RecurrentGCN(torch.nn.Module):\n","\n","    def __init__(self, node_features, num_classes):\n","        super(RecurrentGCN, self).__init__()\n","        self.recurrent_1 = GConvGRU(node_features, 256, 5)\n","        self.linear1 = torch.nn.Linear(256, 256)\n","        self.linear_final = torch.nn.Linear(256, num_classes)\n","\n","    def forward(self, x, edge_index, edge_weight, batch):\n","        x = self.recurrent_1(x, edge_index, edge_weight)\n","        x = F.relu(x)\n","        # x = F.dropout(x, training=self.training)\n","        x = F.relu(x)\n","        # x = F.dropout(x, training=self.training)\n","        x = global_mean_pool(x, batch)\n","\n","        x = F.dropout(x, training=self.training)\n","        x = self.linear1(x)\n","        x = self.linear_final(x)\n","        # return F.log_softmax(x, dim=1)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"-pOjHOf70Xis"},"source":["## Data loading and model training\n"]},{"cell_type":"markdown","metadata":{},"source":["### Data loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31997,"status":"ok","timestamp":1694528692461,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"O8_LFwUwrG20","outputId":"6405ee4a-083f-4c13-fd85-f9c405152c6a"},"outputs":[],"source":["database_path = \"/path/to/database\"\n","\n","N_FILES_TO_LOAD = 32 \n","SECONDS_PER_WINDOW = 5\n","\n","database_data, database_filenames = import_ecg_data(database_path,\n","                                                    seconds_per_window=SECONDS_PER_WINDOW,\n","                                                    n_files_to_load=N_FILES_TO_LOAD)\n","\n","database_data = np.asarray(database_data)\n","database_data = torch.from_numpy(database_data) # convert the data to a PyTorch tensor\n","num_ecg_signals, num_ecg_leads, num_samples = database_data.shape\n","\n","# The calculation of the MI matrix is ommited and the matrix is loaded from an external file\n","\n","# mi = [calc_MI_matrix(database_data[i]) for i in range(num_ecg_signals)]\n","\n","# with open('mi_matrices.npy', 'wb') as f:\n","#     np.save(f, np.array(mi))\n","\n","# with open('mi_matrices.npy', 'rb') as f:\n","#      mi = np.load(f)\n","\n","samples_per_file = 1800/SECONDS_PER_WINDOW\n","\n","# Select only the needed individuals will be selected from the MI matrix\n","\n","mi = mi[0:int(samples_per_file*N_FILES_TO_LOAD)]\n","\n","# We need to reshape to (num_ecg_signals, num_ecg_leads * num_samples)\n","\n","database_data = database_data.view(num_ecg_signals, -1)\n","num_classes = len(np.unique(database_filenames, return_counts=True)[0])\n","\n","print(f\"num_ecg_signals: {num_ecg_signals}\\nnum_classes: {num_classes}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":942,"status":"ok","timestamp":1694528721624,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"q6IVf5YFrG21"},"outputs":[],"source":["# ------ WE NEED TO GENERATE THE EDGE_INDEX IN ORDER TO CREATE THE GRAPH DATASET ------\n","\n","num_nodes = num_ecg_leads\n","edge_index = pyg_ei_fc(num_nodes=num_ecg_leads, self_loops=True)\n","\n","# ------ NEXT, LETS CREATE THE DATASET ---------------------------------------------\n","\n","graph_list = [] # empty list to store the graphs\n","\n","# Generating the tensor of labels\n","\n","real_labels = [int(label.split(\"I\")[1]) for label in database_filenames] # the labels should between 0 and N-1\n","labels = torch.tensor(np.repeat(range(num_classes), np.unique(real_labels, return_counts=True)[1]))\n","\n","\n","for signal_idx in range(num_ecg_signals):\n","    feature_matrix = database_data[signal_idx].reshape(num_ecg_leads, num_samples)  # Reshape to (num_ecg_leads, num_samples)\n","\n","    # Convert feature_matrix and adjacency matrix to PyTorch Geometric data format\n","    x = feature_matrix.clone().detach().float()\n","    edge_index  = edge_index  # fully connected graph with self loops\n","    edge_weight = torch.from_numpy(mi[signal_idx].flatten()).float() # importante el float\n","    # https://discuss.pytorch.org/t/runtimeerror-expected-object-of-scalar-type-double-but-got-scalar-type-float-for-argument-2-weight/38961/13\n","\n","    y = labels[signal_idx].clone().detach()\n","\n","    # Create a PyTorch Geometric data object\n","    graph = tg.data.Data(x=x, edge_index=edge_index, edge_weight=edge_weight, y=y)\n","    graph_list.append(graph)\n","\n","dataset = tg.data.Batch.from_data_list(graph_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":458,"status":"ok","timestamp":1694528762474,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"L19EDj1-NEzV"},"outputs":[],"source":["# We need to create both train and test dataset.\n","# Recall that the train dataset will be used for cross validation, hence for optimizing the parameters of the model.\n","\n","train_indices, test_indices = indices_generator(0, num_ecg_signals, 0.9)\n","\n","train_dataset_complete = dataset[list(train_indices)]\n","test_dataset = dataset[list(test_indices)]"]},{"cell_type":"markdown","metadata":{},"source":["### Training and validating the models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6841,"status":"error","timestamp":1694530294955,"user":{"displayName":"JOSE IGNACIO DIEZ RUIZ","userId":"03187355801185358255"},"user_tz":-120},"id":"NeacJWOuY2zb","outputId":"223b0717-503b-4e81-e8a5-f8127f930ffe"},"outputs":[],"source":["# ---------- DEFINITION OF THE HYPERPARAMETERS ------------------\n","learning_rate = 0.02\n","weight_decay  = 0\n","batch_size    = 128 # Batch size for the loaders\n","num_epochs    = 50\n","num_folds     = 5  # Number of folds for cross-validation\n","criterion     = nn.CrossEntropyLoss()\n","# ---------- LISTS TO STORE THE RESULTS ------------------------------\n","training_accuracy_list      = []\n","training_precision_list     = []\n","training_recall_list        = []\n","training_f1_list            = []\n","validation_accuracy_list    = []\n","validation_precision_list   = []\n","validation_recall_list      = []\n","validation_f1_list          = []\n","# --------- CREATE THE TEST LOADER FOR FUTURE TESTING -----------------------------------\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n","\n","kf = KFold(n_splits=num_folds, shuffle=True)\n","\n","for fold, (train_indices, val_indices) in enumerate(kf.split(dataset)):\n","\n","    train_dataset = dataset[list(train_indices)]\n","    val_dataset   = dataset[list(val_indices)]\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n","\n","    model = GCN(hidden_channels=512)\n","    model = model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    for epoch in range(num_epochs):\n","        train(train_loader, edge_weights=True)\n","\n","        with torch.no_grad():\n","            accuracy_train, precision_train, recall_train, f1score_train, _ = test(train_loader, edge_weights=True)\n","            accuracy_val, precision_val, recall_val, f1score_val, _         = test(val_loader, edge_weights=True)\n","\n","        print(f\"\"\"\n","        Fold [{fold+1}/{num_folds}] - Epoch [{epoch+1}/{num_epochs}]\\n\n","        Train Accuracy: {accuracy_train:.3f} - Validation Accuracy: {accuracy_val:.3f}\\n\n","        Validation Precision: {np.mean(precision_val):.3f} - Validation Recall: {np.mean(recall_val):.3f} - Validation F1: {np.mean(f1score_val):.3f}\\n\n","        -----------------------------------------\n","        \"\"\")\n","\n","        # If it is inside the last epoch, append the results to a list to later visualization\n","        if epoch == (num_epochs - 1):\n","            training_accuracy_list.append(accuracy_train)\n","            training_precision_list.append(np.mean(precision_train))\n","            training_recall_list.append(np.mean(recall_train))\n","            training_f1_list.append(np.mean(f1score_train))\n","\n","            validation_accuracy_list.append(accuracy_val)\n","            validation_precision_list.append(np.mean(precision_val))\n","            validation_recall_list.append(np.mean(recall_val))\n","            validation_f1_list.append(np.mean(f1score_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xxj1CRsjXt5C"},"outputs":[],"source":["# Plot a confusion matrix\n","\n","cm_plot = ConfusionMatrixDisplay(CM, display_labels=[])\n","cm_plot.plot(cmap=plt.cm.Blues, include_values=False)\n","\n","plt.title('Confusion Matrix')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["jeW3FZQgLOHf","NAu32tLPJTdp"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
